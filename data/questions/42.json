{
  "published_iso": "2023-08-28T14:56:00",
  "number": 6,
  "question": "Let's assume that an organization needs to process large amounts of data in bursts, on a cloud-based Kubernetes cluster. For instance: each Monday morning, they need to run a batch of 1000 compute jobs of 1 hour each, and these jobs must be completed by Monday night. What's going to be the most cost-effective method?",
  "options": [
    {
      "key": "A",
      "text": "Run a group of nodes with the exact required size to complete the batch on time, and use a combination of taints, tolerations, and nodeSelectors to reserve these nodes to the batch jobs."
    },
    {
      "key": "B",
      "text": "Leverage the Kubernetes Cluster Autoscaler to automatically start and stop nodes as they're needed."
    },
    {
      "key": "C",
      "text": "Commit to a specific level of spending to get discounted prices (with e.g. \u201creserved instances\u201d or similar mechanisms)."
    },
    {
      "key": "D",
      "text": "Use Priority\u0421lasses so that the weekly batch job gets priority over other workloads running on the cluster, and can be completed on time."
    }
  ],
  "answers": {
    "platform": [
      "B"
    ],
    "community": [
      "B"
    ]
  }
}
